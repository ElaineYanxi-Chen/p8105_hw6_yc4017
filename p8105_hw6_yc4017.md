p8105 Homework 6
================
Elaine Yanxi Chen
2022-12-03

## Packages and settings

First we load the packages necessary to knit this document.

``` r
library(tidyverse)
library(mgcv)
library(modelr)
library(viridis)

knitr::opts_chunk$set(
    echo = TRUE,
    warning = FALSE,
    message = FALSE,
    fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

## Problem 2: Homicides in Baltimore, MD

### Data Import

After loading the dataset, we want to do some initial cleaning and
tidying following these criteria below:

- We want to load the data on homicides in 50 large U.S. cities.
- We want to create a `city_state` variable and a binary variable
  indicating whether the homicide is solved.
- Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO since they do
  not report victim race. Omit Tulsa, AL because this is a data entry
  mistake.
- We will limit the analysis for whom `victim_race` is `white` or
  `black`.
- Make sure that `victim_age` is a numeric variable.

``` r
homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    city_state = str_c(city, state, sep = ","),
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White")
  ) %>% 
  filter(
    !city_state %in% c("Dallas,TX", "Phoenix,AZ", "Kansas City,MO", "Tulsa,AL"),
    victim_race %in% c("White", "Black"))
```

### Baltimore, MD

We are interested in using the `glm` function to fit a logistic
regression model with resolved vs unresolved as the outcome, and victim
age, sex, and race as predictors.

To do so, we will first generate a dataset containing these variables
only.

``` r
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore,MD") %>% 
  select(resolved, victim_age, victim_race, victim_sex)
```

Now we will run the logistic regression model using `glm` and save the
output as an R object.

``` r
fit_logistic = 
  baltimore_df %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) 
```

``` r
glm_baltimore = 
  fit_logistic %>% 
  broom::tidy() %>% 
  janitor::clean_names() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std_error),
    CI_upper = exp(estimate + 1.96 * std_error)) %>% 
  select(-c(std_error, statistic)) 

glm_baltimore %>% 
  knitr::kable(digits = 3)
```

| term             | estimate | p_value |    OR | CI_lower | CI_upper |
|:-----------------|---------:|--------:|------:|---------:|---------:|
| (Intercept)      |    1.152 |   0.000 | 3.164 |    1.989 |    5.031 |
| victim_age       |   -0.007 |   0.043 | 0.993 |    0.987 |    1.000 |
| victim_sexMale   |   -0.854 |   0.000 | 0.426 |    0.325 |    0.558 |
| victim_raceBlack |   -0.842 |   0.000 | 0.431 |    0.306 |    0.607 |

After running the logistic regression model, we want to obtain the
estimate and the confidence interval of the adjusted odds ratio for
solving homicides comparing male victims to female victims keeping all
other variables fixed.

``` r
glm_baltimore %>% 
  filter(term == "victim_sexMale") %>% 
  select(OR:CI_upper) %>% 
  knitr::kable(
    digits = 3,
    col.names = c("Odds Ratio", "Lower 95% CI", "Upper 95% CI"))
```

| Odds Ratio | Lower 95% CI | Upper 95% CI |
|-----------:|-------------:|-------------:|
|      0.426 |        0.325 |        0.558 |

We see that keeping all other variables fixed, homicides in which the
victim is male are 57.4% less likely to be resolved than those in which
the victim is female. We are 95% confident that the true odds ratio for
the association between victimâ€™s sex and resolved homicides lies between
0.325 and 0.558.

### Iterating `glm` for each city
